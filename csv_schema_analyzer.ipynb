{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is used to analyze the schema of a CSV file and return SQL-like schema information.\n",
    "# It reads the CSV file, gets the column information, and outputs the schema information as a string.\n",
    "# The schema information is a string that contains the column name, the data type, and whether the column is nullable.\n",
    "# The output is a string that can be used to create a table in a database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def analyze_csv_schema(csv_file):\n",
    "    \"\"\"Analyze the schema of a CSV file and return SQL-like schema information\"\"\"\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(csv_file)\n",
    "        \n",
    "        # Get column info\n",
    "        schema_info = []\n",
    "        for column in df.dtypes.items():\n",
    "            col_name = column[0]\n",
    "            # Map pandas dtypes to SQL-like types\n",
    "            if 'int' in str(column[1]):\n",
    "                sql_type = 'INTEGER'\n",
    "            elif 'float' in str(column[1]):\n",
    "                sql_type = 'FLOAT'\n",
    "            elif 'datetime' in str(column[1]):\n",
    "                sql_type = 'DATETIME'\n",
    "            elif 'bool' in str(column[1]):\n",
    "                sql_type = 'BOOLEAN'\n",
    "            else:\n",
    "                sql_type = 'VARCHAR'\n",
    "            \n",
    "            # Check if column has any null values\n",
    "            nullable = 'NULL' if df[col_name].isnull().any() else 'NOT NULL'\n",
    "            \n",
    "            schema_info.append(f\"{col_name} {sql_type} {nullable}\")\n",
    "        \n",
    "        # Format schema output\n",
    "        table_name = os.path.splitext(os.path.basename(csv_file))[0].upper()\n",
    "        schema = f\"CREATE TABLE {table_name} (\\n    \" + \",\\n    \".join(schema_info) + \"\\n);\"\n",
    "        \n",
    "        return schema\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error analyzing schema: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE FINAL_FORECAST_SHEET (\n",
      "    id INTEGER NOT NULL,\n",
      "    DC_FC_Assets_Type VARCHAR NULL,\n",
      "    DC_FC_Assets_Name VARCHAR NOT NULL,\n",
      "    SQL_FC_Account_ID VARCHAR NOT NULL,\n",
      "    SQL_Heading_Sequence INTEGER NOT NULL,\n",
      "    SQL_Sequence FLOAT NOT NULL,\n",
      "    SQL_Account_Name_Code VARCHAR NOT NULL,\n",
      "    SQL_Account_Name VARCHAR NOT NULL,\n",
      "    SQL_Account_Category_Order_Code VARCHAR NOT NULL,\n",
      "    SQL_Account_Category_Order VARCHAR NOT NULL,\n",
      "    SUB_Account_Category_Order_Code VARCHAR NULL,\n",
      "    SUB_Account_Category_Order VARCHAR NULL,\n",
      "    SQL_Account_Group_Name_Code FLOAT NULL,\n",
      "    SQL_Account_Group_Name FLOAT NULL,\n",
      "    Accountnumber_ID VARCHAR NOT NULL,\n",
      "    January FLOAT NOT NULL,\n",
      "    February FLOAT NOT NULL,\n",
      "    March FLOAT NOT NULL,\n",
      "    April FLOAT NOT NULL,\n",
      "    May FLOAT NOT NULL,\n",
      "    June FLOAT NOT NULL,\n",
      "    July FLOAT NULL,\n",
      "    August FLOAT NULL,\n",
      "    September FLOAT NULL,\n",
      "    October FLOAT NULL,\n",
      "    November FLOAT NULL,\n",
      "    December FLOAT NULL,\n",
      "    Total FLOAT NULL,\n",
      "    Account_Year INTEGER NOT NULL,\n",
      "    SQL_Property VARCHAR NOT NULL,\n",
      "    updated_at VARCHAR NOT NULL\n",
      ");\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "schema = analyze_csv_schema('final_forecast_sheet.csv')\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error creating database: table FINAL_FORECAST_SHEET already exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nimport glob\\ncsv_files = glob.glob('data/*.csv')  # Gets all CSVs from data directory\\ncreate_database_from_csvs(csv_files)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_database_from_csvs(csv_files, db_name='final_working_database.db'):\n",
    "    \"\"\"\n",
    "    Create a SQLite database from multiple CSV files.\n",
    "    Each CSV file will become a table in the database.\n",
    "    \n",
    "    Args:\n",
    "        csv_files (list): List of CSV file paths\n",
    "        db_name (str): Name of the SQLite database to create\n",
    "    \"\"\"\n",
    "    import sqlite3\n",
    "    \n",
    "    try:\n",
    "        # Create/connect to SQLite database\n",
    "        conn = sqlite3.connect(db_name)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # Process each CSV file\n",
    "        for csv_file in csv_files:\n",
    "            # Get schema for the CSV\n",
    "            create_table_sql = analyze_csv_schema(csv_file)\n",
    "            \n",
    "            # Execute create table statement\n",
    "            cursor.execute(create_table_sql)\n",
    "            \n",
    "            # Read CSV data\n",
    "            df = pd.read_csv(csv_file)\n",
    "            \n",
    "            # Get table name from CSV filename\n",
    "            table_name = os.path.splitext(os.path.basename(csv_file))[0].upper()\n",
    "            \n",
    "            # Insert data into table\n",
    "            df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "            \n",
    "            print(f\"Created table {table_name} and imported data from {csv_file}\")\n",
    "            \n",
    "        conn.commit()\n",
    "        print(f\"\\nDatabase {db_name} created successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating database: {str(e)}\")\n",
    "        \n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Example usage with multiple files:\n",
    "csv_files = [\n",
    "    'final_forecast_sheet.csv',\n",
    "    'final_balance_sheet_tb_new.csv', \n",
    "    'final_balance_sheet_new.csv',\n",
    "    'final_budget_sheet.csv',\n",
    "    'final_income_sheet_new_seq.csv',\n",
    "    'final_income_sheet_tb_new.csv'\n",
    "    # Add more CSV files as needed\n",
    "]\n",
    "create_database_from_csvs(csv_files)\n",
    "\n",
    "# You can also use glob to get all CSV files in a directory:\n",
    "\"\"\"\n",
    "import glob\n",
    "csv_files = glob.glob('data/*.csv')  # Gets all CSVs from data directory\n",
    "create_database_from_csvs(csv_files)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
